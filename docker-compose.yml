version: '3.8'

services:
  # AI Model Provider (Mistral engine)
  ollama:
    image: ollama/ollama:latest
    container_name: ai-ollama
    restart: always
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ai_network

  # Main Web Application (Streamlit)
  ai-detector-web:
    build: .
    container_name: ai-detector-web
    restart: always
    depends_on:
      - ollama
    ports:
      - "8501:8501"
    command: streamlit run app.py --server.port=8501 --server.address=0.0.0.0 --server.enableCORS=false --server.enableXsrfProtection=false
    networks:
      - ai_network

  # Automation Engine (n8n)
  ai-n8n:
    image: n8nio/n8n:latest
    container_name: ai-n8n
    restart: always
    environment:
      - N8N_HOST=n8n.xeniabrunel.com
      - WEBHOOK_URL=https://n8n.xeniabrunel.com/
      - N8N_SECURE_COOKIE=true
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - ai_network

  # Reverse Proxy Manager
  nginx-proxy-manager:
    image: 'jc21/nginx-proxy-manager:latest'
    container_name: nginx-proxy-manager
    restart: always
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    volumes:
      - ./npm_data:/data
      - ./npm_letsencrypt:/etc/letsencrypt
    networks:
      - ai_network

networks:
  ai_network:
    driver: bridge

volumes:
  ollama_data:
  n8n_data:
  npm_data:
  npm_letsencrypt:
